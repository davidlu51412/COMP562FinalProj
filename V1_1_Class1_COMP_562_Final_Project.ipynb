{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V1.1_Class1_COMP_562_Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMrXNqTlDJcSTPbNxpwrQtc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlu51412/COMP562FinalProj/blob/main/V1_1_Class1_COMP_562_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeX8lNGEMU9p"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcRjDWYFP-fl"
      },
      "source": [
        "import os\n",
        "os.mkdir(\"generators\")\n",
        "os.mkdir(\"discriminators\")\n",
        "os.mkdir(\"train_plots\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKreZxjxk2BS"
      },
      "source": [
        "# Create Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ0Kr4xmNwcU"
      },
      "source": [
        "# WE could seperate the class and gan discriminator into two different things,\n",
        "# where they both recieve the generated output individually\n",
        "\n",
        "#  WE CAN PROBABLY PUT DROPOUT LAYERS TO HELP DECREASE OVERTRAINING\n",
        "learning_step = .0001\n",
        "\n",
        "def create_class_discriminator(image_shape, class_dim):\n",
        "  # get convolved image from (base) and try to classify  what class this image is\n",
        "  disc_input = tf.keras.Input(shape=(image_shape))\n",
        "  disc_x = tf.keras.layers.Conv2D(64, (3,3),\n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_input)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Flatten()(disc_x)\n",
        "  disc_x = tf.keras.layers.Dropout(.4)(disc_x)\n",
        "  disc_x = tf.keras.layers.Dense(class_dim, activation=\"sigmoid\")(disc_x)\n",
        "  class_discriminator = tf.keras.Model(inputs=disc_input, outputs=disc_x)\n",
        "  tf.keras.utils.plot_model(class_discriminator, \"class_discriminator.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  class_discriminator.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  return class_discriminator\n",
        "\n",
        "def create_gan_discriminator(image_shape):\n",
        "  # gets convolved image from (base) and try to classify if this is a real or fake image\n",
        "  disc_input = tf.keras.Input(shape=image_shape)\n",
        "  disc_x = tf.keras.layers.Conv2D(64, (3,3),\n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_input)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Flatten()(disc_x)\n",
        "  disc_x = tf.keras.layers.Dropout(.4)(disc_x)\n",
        "  disc_x = tf.keras.layers.Dense(1, activation='sigmoid')(disc_x)\n",
        "  full_discriminator = tf.keras.Model(inputs=disc_input, outputs=disc_x)\n",
        "  tf.keras.utils.plot_model(full_discriminator, \"gan_discriminator.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  full_discriminator.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  return full_discriminator\n",
        "\n",
        "def create_generator(input_dim):\n",
        "  # maybe we can input the generated image into itself\n",
        "  # note: we will pass random noise to this generator\n",
        "  # (in hopes it will generate the correct variations of an object)\n",
        "  # two inputs: random noise and the given image class we want to generate\n",
        "  gen_x_input = tf.keras.Input(shape=(input_dim))\n",
        "  # 4x4 upscaling foundation\n",
        "  num_nodes = 4*4*256 \n",
        "  gen_x = tf.keras.layers.Dense(num_nodes)(gen_x_input)\n",
        "  gen_x = tf.keras.layers.Reshape((4, 4, 256))(gen_x)\n",
        "  # upsize\n",
        "  # 8x8\n",
        "  gen_x = tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),  \n",
        "                                          activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                          padding=\"same\")(gen_x)\n",
        "\n",
        "  # 16x16\n",
        "  gen_x = tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),  \n",
        "                                          activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                          padding=\"same\")(gen_x)\n",
        "  # 32x32\n",
        "  gen_x = tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),  \n",
        "                                          activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                          padding=\"same\")(gen_x)\n",
        "  # 28x28\n",
        "  gen_x = tf.keras.layers.Conv2D(1, (5,5), activation='tanh')(gen_x)\n",
        "  generator = tf.keras.Model(inputs=gen_x_input, outputs=gen_x)\n",
        "  tf.keras.utils.plot_model(generator, \"generator.png\", show_shapes=True)\n",
        "  return generator\n",
        "\n",
        "\n",
        "def create_gan(generator, gan_discriminator, input_dim):\n",
        "  # will be same input as generator\n",
        "  gan_x_input = tf.keras.Input(shape=(input_dim))\n",
        "  gan_x = generator(gan_x_input) \n",
        "\n",
        "  # we want to train the gan to match the classifier and if it's real or fake\n",
        "  real_or_fake = gan_discriminator(gan_x)\n",
        "  gan_discriminator.trainable = False\n",
        "\n",
        "  gan = tf.keras.Model(inputs=gan_x_input, outputs=real_or_fake)\n",
        "  tf.keras.utils.plot_model(gan, \"gan.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  gan.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  \n",
        "  return gan\n",
        "\n",
        "def create_class_discriminator_features(generator, class_discriminator, generator_input_dim):\n",
        "  c_d_features_input = tf.keras.Input(shape=(generator_input_dim))\n",
        "  c_d_features = generator(c_d_features_input)\n",
        "  c_d_features = class_discriminator(c_d_features)\n",
        "  class_discriminator.trainable = False\n",
        "  c_d_features_model = tf.keras.Model(inputs=c_d_features_input, outputs=c_d_features)\n",
        "  tf.keras.utils.plot_model(c_d_features_model, \"c_d_feature.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  c_d_features_model.compile(loss=tf.keras.losses.MeanSquaredError(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  return c_d_features_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfDEhO8Lk4bc"
      },
      "source": [
        "# Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyhFnl4YQdpN"
      },
      "source": [
        "# important functions for training\n",
        "from matplotlib import pyplot\n",
        "import shutil\n",
        "\n",
        "def generate_class_disc_samples(dataset, num_samples, labels):\n",
        "  rand_idx = np.random.randint(0, dataset.shape[0], num_samples)\n",
        "  real_im = dataset[rand_idx]\n",
        "  # real class label of \"1\"\n",
        "  real_label = labels[rand_idx]\n",
        "  return real_im, real_label\n",
        "\n",
        "def generate_real_samples(dataset, num_samples, labels, class_num):\n",
        "  \n",
        "  class_data = dataset[labels==class_num]\n",
        "  # get random \"real\" samples\n",
        "  rand_idx = np.random.randint(0, class_data.shape[0], num_samples)\n",
        "  real_im = class_data[rand_idx]\n",
        "  # real class label of \"1\"\n",
        "  true_class = np.ones((num_samples, 1))  \n",
        "  return real_im, true_class\n",
        "\n",
        "def generate_fake_samples(generator, input_dim, num_samples):\n",
        "  # generate noise input for GAN with randomness and it's own prediction\n",
        "  inputs = np.random.randn(input_dim*num_samples)\n",
        "  # reshape into dimensions for the network\n",
        "  inputs = inputs.reshape(num_samples, input_dim)\n",
        "  fake_im = generator.predict(inputs)\n",
        "  true_class = np.zeros((num_samples, 1))\n",
        "  return fake_im, true_class\n",
        "\n",
        "def generate_GAN_samples(generator, input_dim, num_samples):\n",
        "  # generate noise input for GAN with randomness and it's own prediction\n",
        "  inputs = np.random.randn(input_dim*num_samples)\n",
        "  # reshape into dimensions for the network\n",
        "  inputs = inputs.reshape(num_samples, input_dim)\n",
        "  true_class = np.ones((num_samples, 1))\n",
        "  return inputs, true_class\n",
        "\n",
        "# eval current performance\n",
        "def summarize_performance(epoch, generator, gan_discriminator, dataset, input_dim, labels, class_names, class_num,\n",
        "                          num_samples=150):\n",
        "  # prepare real samples\n",
        "  X_real, real_gan = generate_real_samples(dataset, num_samples, labels, class_num)\n",
        "  # evaluate discriminator on real examples\n",
        "  real_eval = gan_discriminator.evaluate(X_real, real_gan, verbose=0)\n",
        "\n",
        "  # prepare fake examples\n",
        "  x_fake, gan_fake = generate_fake_samples(generator, input_dim, num_samples)\n",
        "  # evaluate discriminator on fake examples\n",
        "  fake_eval = gan_discriminator.evaluate(x_fake, gan_fake, verbose=0)\n",
        "  \n",
        "  # summarize discriminator performance\n",
        "  print(\"____________________\")\n",
        "  print(\"Epoch:\",epoch+1, \"|| Class:\", class_names[class_num])\n",
        "  print(\">real_eval:\", real_eval)\n",
        "  print(\">fake_eval:\", fake_eval)\n",
        "  print(\"____________________\")\n",
        "  # save plot\n",
        "  save_plot(x_fake, epoch, class_names, class_num, 4)\n",
        "  # save the generator model tile file\n",
        "  filename = 'generator_model_' + str(epoch+1) + '_' + class_names[class_num] + '.h5' \n",
        "  generator.save(filename)\n",
        "  shutil.move(filename, './generators/'+filename)\n",
        "\n",
        "  filename = 'gan_discriminator_model_' + str(epoch+1) + '_' + class_names[class_num] + '.h5' \n",
        "  gan_discriminator.save(filename)\n",
        "  shutil.move(filename, './discriminators/'+filename)\n",
        "\n",
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, class_names, class_num, n=4):\n",
        "  # scale from [-1,1] to [0,1]\n",
        "  examples = (examples + 1) / 2.0\n",
        "  # plot images\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "    pyplot.title(class_names[class_num])\n",
        "    pyplot.tight_layout(pad=.5)\n",
        "    # turn off axis\n",
        "    pyplot.axis('off')\n",
        "    # plot raw pixel data\n",
        "    pyplot.imshow(examples[i,:,:,0], cmap=\"gray\")\n",
        "\n",
        "\t# save plot to file\n",
        "  filename = 'generated_plot_e' + str(epoch+1) + '_' + class_names[class_num] + '.png'\n",
        "  pyplot.savefig(filename)\n",
        "  pyplot.close()\n",
        "  shutil.move(filename, './train_plots/'+filename)\n",
        "  \n",
        "\n",
        "def show_rand_plot(generators, input_dim, num_samples, labels, class_names, n=4):\n",
        "  # prepare fake examples\n",
        "  x_fake, true_class = generate_fake_samples(generator, input_dim, num_samples, labels)\n",
        "  # scale from [-1,1] to [0,1]\n",
        "  x_fake = (x_fake + 1) / 2.0\n",
        "  # plot images\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "    pyplot.title(class_names[np.where(real_label[i] == 1)[0][0]])\n",
        "    pyplot.tight_layout(pad=.5)\n",
        "    # turn off axis\n",
        "    pyplot.axis('off')\n",
        "    # plot raw pixel data\n",
        "    pyplot.imshow(x_fake[i,:,:,0], cmap=\"gray\")\n",
        "# train the generator and discriminator\n",
        "def train(generators, gan_discriminators, gans, class_discriminator, cd_features,\n",
        "          dataset, labels, input_dim, sample_num, n_epochs=200, n_batch=128):\n",
        "          \n",
        "  batches_per_epoch = int(dataset.shape[0] / n_batch)\n",
        "  half_batch = int(n_batch / 2)\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_epochs):\n",
        "    # batch training (for 1 epoch)\n",
        "    for j in range(batches_per_epoch):\n",
        "      d_loss_gan_disc_real = 0\n",
        "      d_loss_gan_disc_fake = 0\n",
        "      g_loss = 0\n",
        "      cd_feature_loss = 0\n",
        "      real_im, real_label = generate_class_disc_samples(dataset, half_batch, labels) # train class disc\n",
        "      class_discriminator.train_on_batch(real_im, real_label)\n",
        "      \n",
        "      \n",
        "      for k in range(len(generators)):\n",
        "        # get this classes generators and gan\n",
        "        gan_discriminator = gan_discriminators[k]\n",
        "        generator = generators[k]\n",
        "        gan = gans[k]\n",
        "        cd_feature = cd_features[k]\n",
        "\n",
        "        real_im, _ = generate_real_samples(dataset, half_batch, labels, k)\n",
        "        class_disc_features = class_discriminator.predict(real_im) # get this classes' expected feature from class disc\n",
        "        cd_input, _ = generate_GAN_samples(generator, input_dim, half_batch) # get noise for cd_feature input\n",
        "        cd_feature_loss_local, _ = cd_feature.train_on_batch(cd_input, class_disc_features)\n",
        "        cd_feature_loss += cd_feature_loss_local\n",
        "        \n",
        "        real_im, real_gan = generate_real_samples(dataset, half_batch, labels, k)\n",
        "        d_loss_real_local, _ = gan_discriminator.train_on_batch(real_im, real_gan) # gan loss real\n",
        "        d_loss_gan_disc_real += d_loss_real_local\n",
        "        fake_im, fake_gan = generate_fake_samples(generator, input_dim, half_batch)\n",
        "        d_loss_fake_local, _ = gan_discriminator.train_on_batch(fake_im, fake_gan) # gan loss fake\n",
        "        d_loss_gan_disc_fake += d_loss_fake_local\n",
        "\n",
        "        gan_input, inverted_label = generate_GAN_samples(generator, input_dim, half_batch) # returns with random noise for gan input\n",
        "        g_loss_local, _ = gan.train_on_batch(gan_input, inverted_label) # train generator with inverted labels via gan\n",
        "        g_loss += g_loss_local\n",
        "      # summarize loss on this batch\n",
        "      if (j+1) % n_batch == 0:\n",
        "        print(\"Epoch:\", i+1, \" - Batch:\",str(j+1)+\"/\"+str(batches_per_epoch),\n",
        "              \"avg_d_loss_gan (real/fake):\" + str(d_loss_gan_disc_real/len(labels)) + \",\" + str(d_loss_gan_disc_fake/len(labels)),\n",
        "              \"avg_gan_loss:\" + str(g_loss/len(labels)),\"cd_feature_loss:\" + str(cd_feature_loss/len(labels)))\n",
        "    # evaluate the model performance, sometimes\n",
        "    if (i+1) % 10 == 0:\n",
        "      for k in range(len(generators)):\n",
        "        summarize_performance(i, generators[k], gan_discriminators[k], dataset, input_dim, labels, class_names, k, sample_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35jPqfM7k6S-"
      },
      "source": [
        "# Init and Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12H6tp3NDcQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5069542c-7d1d-4f48-cc7b-0e2b93d7604e"
      },
      "source": [
        "# initializations before training\n",
        "# load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "class_names = ['zero', 'one', 'two', 'three', 'four',\n",
        "               'five', 'six', 'seven', 'eight', 'nine']\n",
        "# for tensorflow format (they assume 3rd dimension with color channels)\n",
        "train_images = np.expand_dims(train_images, 3)\n",
        "train_images = np.interp(train_images, (train_images.min(), train_images.max()), (-1, +1))\n",
        "\n",
        "test_images = np.expand_dims(test_images, 3)\n",
        "test_images = np.interp(test_images, (test_images.min(), test_images.max()), (-1, +1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyywK4qm3g80"
      },
      "source": [
        "im_shape = train_images[0].shape  # is the noise dim\n",
        "sample_num = 16 # make this a full square\n",
        "# length of noise vector for random generation\n",
        "label_shape = len(class_names)\n",
        "generator_input_dim = 100\n",
        "# init the generator array\n",
        "generators = []\n",
        "gans = []\n",
        "gan_discriminators = []\n",
        "class_discriminator = create_class_discriminator(im_shape, label_shape,)\n",
        "cd_features = []\n",
        "\n",
        "# create the generator array\n",
        "for i in range(label_shape):\n",
        "  generators.append(create_generator(generator_input_dim))\n",
        "  gan_discriminators.append(create_gan_discriminator(im_shape))\n",
        "  gans.append(create_gan(generators[i], gan_discriminators[i], generator_input_dim))\n",
        "  cd_features.append(create_class_discriminator_features(generators[i], class_discriminator, generator_input_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgHPtTZcf5QM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afc48b44-af3f-4bcc-e1b1-e151da872295"
      },
      "source": [
        "train(generators, gan_discriminators, gans, class_discriminator,  cd_features,\n",
        "      train_images, train_labels, generator_input_dim, sample_num, n_epochs=1000, \n",
        "      n_batch=1024)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5b9807c3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5bd06acb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5be6725680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 10 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5be59d14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5bd07629e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5bd05fef80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5bd0605dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5b98079560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5908b7b5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5907224b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f590690bd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5906829d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5904ddddd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f59044d5050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f59042b7ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f59029b54d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f59020a5c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5900627950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f590052cef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58ffbd10e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58ff9aadd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58fe038710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58fd7a08c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58fd5905f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58fbc5c9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58fb35c3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f58fb14a200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: zero\n",
            ">real_eval: [0.357504665851593, 0.9375]\n",
            ">fake_eval: [0.47031107544898987, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 10 || Class: one\n",
            ">real_eval: [0.6140294671058655, 0.75]\n",
            ">fake_eval: [0.6264340877532959, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 10 || Class: two\n",
            ">real_eval: [0.7770315408706665, 0.625]\n",
            ">fake_eval: [0.3382793664932251, 0.875]\n",
            "____________________\n",
            "WARNING:tensorflow:5 out of the last 185300 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5be59b17a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: three\n",
            ">real_eval: [0.3828827440738678, 0.8125]\n",
            ">fake_eval: [0.33611831068992615, 0.9375]\n",
            "____________________\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f58e9ce65f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 185301 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5bd02684d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: four\n",
            ">real_eval: [0.06815672665834427, 1.0]\n",
            ">fake_eval: [0.0802386924624443, 1.0]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f58f862ca70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 185302 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f590437a5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: five\n",
            ">real_eval: [0.22110377252101898, 0.875]\n",
            ">fake_eval: [0.14747223258018494, 1.0]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f58e73af950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 185303 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5901ee4200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: six\n",
            ">real_eval: [0.3401579260826111, 0.9375]\n",
            ">fake_eval: [0.40418776869773865, 0.9375]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f58e5ec9b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 185304 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58ffadf4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: seven\n",
            ">real_eval: [0.18269085884094238, 0.9375]\n",
            ">fake_eval: [0.23748262226581573, 1.0]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f58e4a67d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 185305 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58fd639cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: eight\n",
            ">real_eval: [0.4120687246322632, 0.875]\n",
            ">fake_eval: [0.21842586994171143, 0.875]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f58e3581f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 185306 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58fb1f47a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 10 || Class: nine\n",
            ">real_eval: [0.216537207365036, 0.875]\n",
            ">fake_eval: [0.2757640480995178, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: zero\n",
            ">real_eval: [0.7765024900436401, 0.625]\n",
            ">fake_eval: [0.4575360417366028, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: one\n",
            ">real_eval: [0.41475561261177063, 0.75]\n",
            ">fake_eval: [0.5828424692153931, 0.5625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: two\n",
            ">real_eval: [0.38262075185775757, 0.8125]\n",
            ">fake_eval: [0.33066481351852417, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: three\n",
            ">real_eval: [0.3503541946411133, 0.875]\n",
            ">fake_eval: [0.43243563175201416, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: four\n",
            ">real_eval: [0.41190361976623535, 0.6875]\n",
            ">fake_eval: [0.3673505187034607, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: five\n",
            ">real_eval: [0.34413403272628784, 0.875]\n",
            ">fake_eval: [0.47938504815101624, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: six\n",
            ">real_eval: [0.5762301683425903, 0.6875]\n",
            ">fake_eval: [0.3573324978351593, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: seven\n",
            ">real_eval: [0.38300472497940063, 0.8125]\n",
            ">fake_eval: [0.3577827215194702, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: eight\n",
            ">real_eval: [0.4290447235107422, 0.75]\n",
            ">fake_eval: [0.3191368579864502, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: nine\n",
            ">real_eval: [0.1824464201927185, 1.0]\n",
            ">fake_eval: [0.17206619679927826, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: zero\n",
            ">real_eval: [0.37422263622283936, 0.875]\n",
            ">fake_eval: [0.4599127173423767, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: one\n",
            ">real_eval: [0.6194949150085449, 0.5]\n",
            ">fake_eval: [0.5936784148216248, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: two\n",
            ">real_eval: [0.8278915882110596, 0.6875]\n",
            ">fake_eval: [0.40193986892700195, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: three\n",
            ">real_eval: [0.24700158834457397, 0.875]\n",
            ">fake_eval: [0.41243061423301697, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: four\n",
            ">real_eval: [0.550533652305603, 0.75]\n",
            ">fake_eval: [0.5254905223846436, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: five\n",
            ">real_eval: [0.4388102889060974, 0.8125]\n",
            ">fake_eval: [0.3892194628715515, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: six\n",
            ">real_eval: [0.3423119783401489, 0.8125]\n",
            ">fake_eval: [0.60304194688797, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: seven\n",
            ">real_eval: [0.2938340902328491, 0.875]\n",
            ">fake_eval: [0.4546675980091095, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: eight\n",
            ">real_eval: [0.24539200961589813, 1.0]\n",
            ">fake_eval: [0.3450878858566284, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 30 || Class: nine\n",
            ">real_eval: [0.33761823177337646, 0.875]\n",
            ">fake_eval: [0.44808459281921387, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: zero\n",
            ">real_eval: [0.8589996099472046, 0.3125]\n",
            ">fake_eval: [0.5515621304512024, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: one\n",
            ">real_eval: [0.6535627841949463, 0.5]\n",
            ">fake_eval: [0.5271526575088501, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: two\n",
            ">real_eval: [0.5708264112472534, 0.75]\n",
            ">fake_eval: [0.48536598682403564, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: three\n",
            ">real_eval: [0.44293975830078125, 0.875]\n",
            ">fake_eval: [0.47244635224342346, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: four\n",
            ">real_eval: [0.3568630814552307, 0.875]\n",
            ">fake_eval: [0.24835239350795746, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: five\n",
            ">real_eval: [0.5817350149154663, 0.625]\n",
            ">fake_eval: [0.5911075472831726, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: six\n",
            ">real_eval: [0.4158617854118347, 0.75]\n",
            ">fake_eval: [0.2844783067703247, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: seven\n",
            ">real_eval: [0.34064754843711853, 0.8125]\n",
            ">fake_eval: [0.35534852743148804, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: eight\n",
            ">real_eval: [0.8105703592300415, 0.5625]\n",
            ">fake_eval: [0.5968303084373474, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: nine\n",
            ">real_eval: [0.43810856342315674, 0.8125]\n",
            ">fake_eval: [0.3958693742752075, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: zero\n",
            ">real_eval: [0.6432307958602905, 0.75]\n",
            ">fake_eval: [0.5576268434524536, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: one\n",
            ">real_eval: [0.6985411643981934, 0.5]\n",
            ">fake_eval: [0.7158689498901367, 0.4375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: two\n",
            ">real_eval: [0.4821151793003082, 0.75]\n",
            ">fake_eval: [0.5894154906272888, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: three\n",
            ">real_eval: [0.48505899310112, 0.75]\n",
            ">fake_eval: [0.6763981580734253, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: four\n",
            ">real_eval: [0.26629382371902466, 0.875]\n",
            ">fake_eval: [0.2643076181411743, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: five\n",
            ">real_eval: [0.5130397081375122, 0.75]\n",
            ">fake_eval: [0.7009004354476929, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: six\n",
            ">real_eval: [0.44434839487075806, 0.875]\n",
            ">fake_eval: [0.3405567407608032, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: seven\n",
            ">real_eval: [0.3791862428188324, 0.75]\n",
            ">fake_eval: [0.3563569188117981, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: eight\n",
            ">real_eval: [0.758781909942627, 0.6875]\n",
            ">fake_eval: [0.3658919334411621, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 50 || Class: nine\n",
            ">real_eval: [0.4429358243942261, 0.75]\n",
            ">fake_eval: [0.5300406813621521, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: zero\n",
            ">real_eval: [0.5250483751296997, 0.6875]\n",
            ">fake_eval: [0.5142295360565186, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: one\n",
            ">real_eval: [0.6717996597290039, 0.5625]\n",
            ">fake_eval: [0.48487454652786255, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: two\n",
            ">real_eval: [0.5839568972587585, 0.75]\n",
            ">fake_eval: [0.5140933990478516, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: three\n",
            ">real_eval: [0.3545549511909485, 0.875]\n",
            ">fake_eval: [0.32207655906677246, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: four\n",
            ">real_eval: [0.3580087423324585, 0.875]\n",
            ">fake_eval: [0.44473350048065186, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: five\n",
            ">real_eval: [0.8516916036605835, 0.375]\n",
            ">fake_eval: [0.5831433534622192, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: six\n",
            ">real_eval: [0.4345201253890991, 0.6875]\n",
            ">fake_eval: [0.4321770668029785, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: seven\n",
            ">real_eval: [0.5627769231796265, 0.6875]\n",
            ">fake_eval: [0.4843830168247223, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: eight\n",
            ">real_eval: [0.5087444186210632, 0.75]\n",
            ">fake_eval: [0.6213391423225403, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: nine\n",
            ">real_eval: [0.6645995378494263, 0.4375]\n",
            ">fake_eval: [0.47788938879966736, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: zero\n",
            ">real_eval: [0.6780754923820496, 0.5]\n",
            ">fake_eval: [0.6155852675437927, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: one\n",
            ">real_eval: [0.5089632272720337, 0.6875]\n",
            ">fake_eval: [0.5118824243545532, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: two\n",
            ">real_eval: [0.383499413728714, 0.875]\n",
            ">fake_eval: [0.4244644045829773, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: three\n",
            ">real_eval: [0.3782392144203186, 0.9375]\n",
            ">fake_eval: [0.47761720418930054, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: four\n",
            ">real_eval: [0.41665810346603394, 0.75]\n",
            ">fake_eval: [0.4550507068634033, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: five\n",
            ">real_eval: [0.5273027420043945, 0.75]\n",
            ">fake_eval: [0.5129092335700989, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: six\n",
            ">real_eval: [1.2420897483825684, 0.5625]\n",
            ">fake_eval: [2.005216121673584, 0.1875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: seven\n",
            ">real_eval: [0.7263795137405396, 0.5]\n",
            ">fake_eval: [0.42052021622657776, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: eight\n",
            ">real_eval: [0.4088093638420105, 0.75]\n",
            ">fake_eval: [0.5206997394561768, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 70 || Class: nine\n",
            ">real_eval: [0.7487528324127197, 0.625]\n",
            ">fake_eval: [0.4654636085033417, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: zero\n",
            ">real_eval: [0.41900694370269775, 0.6875]\n",
            ">fake_eval: [0.5969129204750061, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: one\n",
            ">real_eval: [0.4827061891555786, 0.75]\n",
            ">fake_eval: [0.5961742401123047, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: two\n",
            ">real_eval: [0.3529133200645447, 0.8125]\n",
            ">fake_eval: [0.4761661887168884, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: three\n",
            ">real_eval: [0.40876439213752747, 0.75]\n",
            ">fake_eval: [0.3693044185638428, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: four\n",
            ">real_eval: [0.3715285658836365, 0.75]\n",
            ">fake_eval: [0.29398834705352783, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: five\n",
            ">real_eval: [0.7205291986465454, 0.625]\n",
            ">fake_eval: [0.5256097912788391, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: six\n",
            ">real_eval: [0.38592275977134705, 0.8125]\n",
            ">fake_eval: [0.47314006090164185, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: seven\n",
            ">real_eval: [0.5009751319885254, 0.625]\n",
            ">fake_eval: [0.4508887529373169, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: eight\n",
            ">real_eval: [0.6106897592544556, 0.5]\n",
            ">fake_eval: [0.4980084300041199, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: nine\n",
            ">real_eval: [0.5734109878540039, 0.5625]\n",
            ">fake_eval: [0.48186400532722473, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: zero\n",
            ">real_eval: [0.23024767637252808, 1.0]\n",
            ">fake_eval: [0.5059424638748169, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: one\n",
            ">real_eval: [0.3474057912826538, 0.8125]\n",
            ">fake_eval: [0.5095565319061279, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: two\n",
            ">real_eval: [0.35914507508277893, 0.8125]\n",
            ">fake_eval: [0.37990492582321167, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: three\n",
            ">real_eval: [0.6402087807655334, 0.5625]\n",
            ">fake_eval: [0.6461113691329956, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: four\n",
            ">real_eval: [0.7253400087356567, 0.625]\n",
            ">fake_eval: [0.5440950393676758, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: five\n",
            ">real_eval: [0.6183622479438782, 0.6875]\n",
            ">fake_eval: [0.5568766593933105, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: six\n",
            ">real_eval: [0.5540350675582886, 0.6875]\n",
            ">fake_eval: [0.5035887360572815, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: seven\n",
            ">real_eval: [0.4261415898799896, 0.8125]\n",
            ">fake_eval: [0.46680042147636414, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: eight\n",
            ">real_eval: [0.366487979888916, 0.875]\n",
            ">fake_eval: [0.47465819120407104, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 90 || Class: nine\n",
            ">real_eval: [0.37965914607048035, 0.75]\n",
            ">fake_eval: [0.28643184900283813, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: zero\n",
            ">real_eval: [0.8805545568466187, 0.4375]\n",
            ">fake_eval: [0.5753127336502075, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: one\n",
            ">real_eval: [0.7634952068328857, 0.5]\n",
            ">fake_eval: [0.6339945793151855, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: two\n",
            ">real_eval: [0.3742698132991791, 0.8125]\n",
            ">fake_eval: [0.45069655776023865, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: three\n",
            ">real_eval: [0.21633130311965942, 0.9375]\n",
            ">fake_eval: [0.1004239022731781, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: four\n",
            ">real_eval: [0.41082334518432617, 0.6875]\n",
            ">fake_eval: [0.5210235118865967, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: five\n",
            ">real_eval: [0.5862779021263123, 0.6875]\n",
            ">fake_eval: [0.30204975605010986, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: six\n",
            ">real_eval: [0.5419654846191406, 0.625]\n",
            ">fake_eval: [0.6499594449996948, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: seven\n",
            ">real_eval: [0.5571777820587158, 0.6875]\n",
            ">fake_eval: [0.42056626081466675, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: eight\n",
            ">real_eval: [0.4668908715248108, 0.75]\n",
            ">fake_eval: [0.6078237891197205, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: nine\n",
            ">real_eval: [0.3358311057090759, 0.9375]\n",
            ">fake_eval: [0.4535033702850342, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: zero\n",
            ">real_eval: [0.462734580039978, 0.8125]\n",
            ">fake_eval: [0.5552697777748108, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: one\n",
            ">real_eval: [1.1472501754760742, 0.3125]\n",
            ">fake_eval: [0.5537554025650024, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: two\n",
            ">real_eval: [0.6610472202301025, 0.6875]\n",
            ">fake_eval: [0.4456214904785156, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: three\n",
            ">real_eval: [0.8806736469268799, 0.5]\n",
            ">fake_eval: [0.4899771511554718, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: four\n",
            ">real_eval: [0.4662242829799652, 0.625]\n",
            ">fake_eval: [0.4222615659236908, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: five\n",
            ">real_eval: [0.48672839999198914, 0.8125]\n",
            ">fake_eval: [0.48577195405960083, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: six\n",
            ">real_eval: [0.7568727731704712, 0.4375]\n",
            ">fake_eval: [0.46039554476737976, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: seven\n",
            ">real_eval: [0.25146710872650146, 0.8125]\n",
            ">fake_eval: [0.47613635659217834, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: eight\n",
            ">real_eval: [0.5023707151412964, 0.75]\n",
            ">fake_eval: [0.3486470878124237, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 110 || Class: nine\n",
            ">real_eval: [0.5315269231796265, 0.75]\n",
            ">fake_eval: [0.5380916595458984, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: zero\n",
            ">real_eval: [0.661450982093811, 0.625]\n",
            ">fake_eval: [0.5004563331604004, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: one\n",
            ">real_eval: [0.5402631163597107, 0.625]\n",
            ">fake_eval: [0.5681368708610535, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: two\n",
            ">real_eval: [0.581513524055481, 0.5625]\n",
            ">fake_eval: [0.480514258146286, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: three\n",
            ">real_eval: [0.5652542114257812, 0.6875]\n",
            ">fake_eval: [0.4573902487754822, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: four\n",
            ">real_eval: [0.5600969791412354, 0.75]\n",
            ">fake_eval: [0.29457855224609375, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: five\n",
            ">real_eval: [0.6746317148208618, 0.625]\n",
            ">fake_eval: [0.47865790128707886, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: six\n",
            ">real_eval: [0.5196993350982666, 0.8125]\n",
            ">fake_eval: [0.4449920654296875, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: seven\n",
            ">real_eval: [0.4556429386138916, 0.6875]\n",
            ">fake_eval: [0.41570720076560974, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: eight\n",
            ">real_eval: [0.4588387608528137, 0.75]\n",
            ">fake_eval: [0.4578346312046051, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: nine\n",
            ">real_eval: [0.38675928115844727, 0.875]\n",
            ">fake_eval: [0.4781290292739868, 0.9375]\n",
            "____________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-57228b75431d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train(generators, gan_discriminators, gans, class_discriminator,  cd_features,\n\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_input_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       n_batch=1024)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-1f7b8acb3ca1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(generators, gan_discriminators, gans, class_discriminator, cd_features, dataset, labels, input_dim, sample_num, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0md_loss_gan_disc_real\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss_real_local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mfake_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0md_loss_fake_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_gan\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gan loss fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0md_loss_gan_disc_fake\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss_fake_local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m     \"\"\"\n\u001b[1;32m   1668\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   def train_on_batch(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3704\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3706\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    891\u001b[0m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[1;32m    892\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 893\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    894\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 142\u001b[0;31m         _ctx, \"AssignVariableOp\", name, resource, value)\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGFk7tbSUA9T"
      },
      "source": [
        "show_rand_plot(generator, im_shape, sample_num, train_labels, class_names, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN2_KMGaUZ8r"
      },
      "source": [
        "import time\n",
        "for i in range(12):\n",
        "  time.sleep(60*60)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
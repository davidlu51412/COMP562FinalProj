{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V1.1_NoClass_COMP_562_Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wKreZxjxk2BS",
        "FfDEhO8Lk4bc",
        "35jPqfM7k6S-"
      ],
      "authorship_tag": "ABX9TyPNCffE/dIHgADu6II6rrww",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlu51412/COMP562FinalProj/blob/main/V1_1_NoClass_COMP_562_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeX8lNGEMU9p"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcRjDWYFP-fl"
      },
      "source": [
        "import os\n",
        "os.mkdir(\"generators\")\n",
        "os.mkdir(\"discriminators\")\n",
        "os.mkdir(\"train_plots\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKreZxjxk2BS"
      },
      "source": [
        "# Create Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ0Kr4xmNwcU"
      },
      "source": [
        "# WE could seperate the class and gan discriminator into two different things,\n",
        "# where they both recieve the generated output individually\n",
        "\n",
        "#  WE CAN PROBABLY PUT DROPOUT LAYERS TO HELP DECREASE OVERTRAINING\n",
        "learning_step = .0001\n",
        "\n",
        "def create_class_discriminator(image_shape, class_dim):\n",
        "  # get convolved image from (base) and try to classify  what class this image is\n",
        "  disc_input = tf.keras.Input(shape=(image_shape))\n",
        "  disc_x = tf.keras.layers.Conv2D(64, (3,3),\n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_input)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Flatten()(disc_x)\n",
        "  disc_x = tf.keras.layers.Dropout(.4)(disc_x)\n",
        "  disc_x = tf.keras.layers.Dense(class_dim, activation=\"sigmoid\")(disc_x)\n",
        "  class_discriminator = tf.keras.Model(inputs=disc_input, outputs=disc_x)\n",
        "  tf.keras.utils.plot_model(class_discriminator, \"class_discriminator.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  class_discriminator.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  return class_discriminator\n",
        "\n",
        "def create_gan_discriminator(image_shape):\n",
        "  # gets convolved image from (base) and try to classify if this is a real or fake image\n",
        "  disc_input = tf.keras.Input(shape=image_shape)\n",
        "  disc_x = tf.keras.layers.Conv2D(64, (3,3),\n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_input)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), \n",
        "                                  activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                  padding='same')(disc_x)\n",
        "  disc_x = tf.keras.layers.Flatten()(disc_x)\n",
        "  disc_x = tf.keras.layers.Dropout(.4)(disc_x)\n",
        "  disc_x = tf.keras.layers.Dense(1, activation='sigmoid')(disc_x)\n",
        "  full_discriminator = tf.keras.Model(inputs=disc_input, outputs=disc_x)\n",
        "  tf.keras.utils.plot_model(full_discriminator, \"gan_discriminator.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  full_discriminator.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  return full_discriminator\n",
        "\n",
        "def create_generator(input_dim):\n",
        "  # maybe we can input the generated image into itself\n",
        "  # note: we will pass random noise to this generator\n",
        "  # (in hopes it will generate the correct variations of an object)\n",
        "  # two inputs: random noise and the given image class we want to generate\n",
        "  gen_x_input = tf.keras.Input(shape=(input_dim))\n",
        "  # 4x4 upscaling foundation\n",
        "  num_nodes = 4*4*256 \n",
        "  gen_x = tf.keras.layers.Dense(num_nodes)(gen_x_input)\n",
        "  gen_x = tf.keras.layers.Reshape((4, 4, 256))(gen_x)\n",
        "  # upsize\n",
        "  # 8x8\n",
        "  gen_x = tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),  \n",
        "                                          activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                          padding=\"same\")(gen_x)\n",
        "\n",
        "  # 16x16\n",
        "  gen_x = tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),  \n",
        "                                          activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                          padding=\"same\")(gen_x)\n",
        "  # 32x32\n",
        "  gen_x = tf.keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),  \n",
        "                                          activation=tf.keras.layers.LeakyReLU(.2),\n",
        "                                          padding=\"same\")(gen_x)\n",
        "  # 28x28\n",
        "  gen_x = tf.keras.layers.Conv2D(1, (5,5), activation='tanh')(gen_x)\n",
        "  generator = tf.keras.Model(inputs=gen_x_input, outputs=gen_x)\n",
        "  tf.keras.utils.plot_model(generator, \"generator.png\", show_shapes=True)\n",
        "  return generator\n",
        "\n",
        "\n",
        "def create_gan(generator, gan_discriminator, input_dim):\n",
        "  # will be same input as generator\n",
        "  gan_x_input = tf.keras.Input(shape=(input_dim))\n",
        "  gan_x = generator(gan_x_input) \n",
        "\n",
        "  # we want to train the gan to match the classifier and if it's real or fake\n",
        "  real_or_fake = gan_discriminator(gan_x)\n",
        "  gan_discriminator.trainable = False\n",
        "\n",
        "  gan = tf.keras.Model(inputs=gan_x_input, outputs=real_or_fake)\n",
        "  tf.keras.utils.plot_model(gan, \"gan.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  gan.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  \n",
        "  return gan\n",
        "\n",
        "def create_class_discriminator_features(generator, class_discriminator, generator_input_dim):\n",
        "  c_d_features_input = tf.keras.Input(shape=(generator_input_dim))\n",
        "  c_d_features = generator(c_d_features_input)\n",
        "  c_d_features = class_discriminator(c_d_features)\n",
        "  class_discriminator.trainable = False\n",
        "  c_d_features_model = tf.keras.Model(inputs=c_d_features_input, outputs=c_d_features)\n",
        "  tf.keras.utils.plot_model(c_d_features_model, \"c_d_feature.png\", show_shapes=True)\n",
        "  optimizerfn = tf.keras.optimizers.Adam(learning_rate=learning_step, beta_1=.9)\n",
        "  c_d_features_model.compile(loss=tf.keras.losses.MeanSquaredError(), \n",
        "                        optimizer=optimizerfn, metrics=['accuracy'])\n",
        "  return c_d_features_model\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfDEhO8Lk4bc"
      },
      "source": [
        "# Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyhFnl4YQdpN"
      },
      "source": [
        "# important functions for training\n",
        "from matplotlib import pyplot\n",
        "import shutil\n",
        "\n",
        "def generate_class_disc_samples(dataset, num_samples, labels):\n",
        "  rand_idx = np.random.randint(0, dataset.shape[0], num_samples)\n",
        "  real_im = dataset[rand_idx]\n",
        "  # real class label of \"1\"\n",
        "  real_label = labels[rand_idx]\n",
        "  return real_im, real_label\n",
        "\n",
        "def generate_real_samples(dataset, num_samples, labels, class_num):\n",
        "  \n",
        "  class_data = dataset[labels==class_num]\n",
        "  # get random \"real\" samples\n",
        "  rand_idx = np.random.randint(0, class_data.shape[0], num_samples)\n",
        "  real_im = class_data[rand_idx]\n",
        "  # real class label of \"1\"\n",
        "  true_class = np.ones((num_samples, 1))  \n",
        "  return real_im, true_class\n",
        "\n",
        "def generate_fake_samples(generator, input_dim, num_samples):\n",
        "  # generate noise input for GAN with randomness and it's own prediction\n",
        "  inputs = np.random.randn(input_dim*num_samples)\n",
        "  # reshape into dimensions for the network\n",
        "  inputs = inputs.reshape(num_samples, input_dim)\n",
        "  fake_im = generator.predict(inputs)\n",
        "  true_class = np.zeros((num_samples, 1))\n",
        "  return fake_im, true_class\n",
        "\n",
        "def generate_GAN_samples(generator, input_dim, num_samples):\n",
        "  # generate noise input for GAN with randomness and it's own prediction\n",
        "  inputs = np.random.randn(input_dim*num_samples)\n",
        "  # reshape into dimensions for the network\n",
        "  inputs = inputs.reshape(num_samples, input_dim)\n",
        "  true_class = np.ones((num_samples, 1))\n",
        "  return inputs, true_class\n",
        "\n",
        "# eval current performance\n",
        "def summarize_performance(epoch, generator, gan_discriminator, dataset, input_dim, labels, class_names, class_num,\n",
        "                          num_samples=150):\n",
        "  # prepare real samples\n",
        "  X_real, real_gan = generate_real_samples(dataset, num_samples, labels, class_num)\n",
        "  # evaluate discriminator on real examples\n",
        "  real_eval = gan_discriminator.evaluate(X_real, real_gan, verbose=0)\n",
        "\n",
        "  # prepare fake examples\n",
        "  x_fake, gan_fake = generate_fake_samples(generator, input_dim, num_samples)\n",
        "  # evaluate discriminator on fake examples\n",
        "  fake_eval = gan_discriminator.evaluate(x_fake, gan_fake, verbose=0)\n",
        "  \n",
        "  # summarize discriminator performance\n",
        "  print(\"____________________\")\n",
        "  print(\"Epoch:\",epoch+1, \"|| Class:\", class_names[class_num])\n",
        "  print(\">real_eval:\", real_eval)\n",
        "  print(\">fake_eval:\", fake_eval)\n",
        "  print(\"____________________\")\n",
        "  # save plot\n",
        "  save_plot(x_fake, epoch, class_names, class_num, 4)\n",
        "  # save the generator model tile file\n",
        "  filename = 'generator_model_' + str(epoch+1) + '_' + class_names[class_num] + '.h5' \n",
        "  generator.save(filename)\n",
        "  shutil.move(filename, './generators/'+filename)\n",
        "\n",
        "  filename = 'gan_discriminator_model_' + str(epoch+1) + '_' + class_names[class_num] + '.h5' \n",
        "  gan_discriminator.save(filename)\n",
        "  shutil.move(filename, './discriminators/'+filename)\n",
        "\n",
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, class_names, class_num, n=4):\n",
        "  # scale from [-1,1] to [0,1]\n",
        "  examples = (examples + 1) / 2.0\n",
        "  # plot images\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "    pyplot.title(class_names[class_num])\n",
        "    pyplot.tight_layout(pad=.5)\n",
        "    # turn off axis\n",
        "    pyplot.axis('off')\n",
        "    # plot raw pixel data\n",
        "    pyplot.imshow(examples[i,:,:,0], cmap=\"gray\")\n",
        "\n",
        "\t# save plot to file\n",
        "  filename = 'generated_plot_e' + str(epoch+1) + '_' + class_names[class_num] + '.png'\n",
        "  pyplot.savefig(filename)\n",
        "  pyplot.close()\n",
        "  shutil.move(filename, './train_plots/'+filename)\n",
        "  \n",
        "\n",
        "def show_rand_plot(generators, input_dim, num_samples, labels, class_names, n=4):\n",
        "  # prepare fake examples\n",
        "  x_fake, true_class = generate_fake_samples(generator, input_dim, num_samples, labels)\n",
        "  # scale from [-1,1] to [0,1]\n",
        "  x_fake = (x_fake + 1) / 2.0\n",
        "  # plot images\n",
        "  for i in range(n * n):\n",
        "    # define subplot\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "    pyplot.title(class_names[np.where(real_label[i] == 1)[0][0]])\n",
        "    pyplot.tight_layout(pad=.5)\n",
        "    # turn off axis\n",
        "    pyplot.axis('off')\n",
        "    # plot raw pixel data\n",
        "    pyplot.imshow(x_fake[i,:,:,0], cmap=\"gray\")\n",
        "# train the generator and discriminator\n",
        "def train(generators, gan_discriminators, gans, class_discriminator, cd_features,\n",
        "          dataset, labels, input_dim, sample_num, n_epochs=200, n_batch=128):\n",
        "          \n",
        "  batches_per_epoch = int(dataset.shape[0] / n_batch)\n",
        "  half_batch = int(n_batch / 2)\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_epochs):\n",
        "    # batch training (for 1 epoch)\n",
        "    for j in range(batches_per_epoch):\n",
        "      d_loss_gan_disc_real = 0\n",
        "      d_loss_gan_disc_fake = 0\n",
        "      g_loss = 0\n",
        "      cd_feature_loss = 0\n",
        "      # real_im, real_label = generate_class_disc_samples(dataset, half_batch, labels) # train class disc\n",
        "      # class_discriminator.train_on_batch(real_im, real_label)\n",
        "      \n",
        "      \n",
        "      for k in range(len(generators)):\n",
        "        # get this classes generators and gan\n",
        "        gan_discriminator = gan_discriminators[k]\n",
        "        generator = generators[k]\n",
        "        gan = gans[k]\n",
        "        cd_feature = cd_features[k]\n",
        "\n",
        "        # real_im, _ = generate_real_samples(dataset, half_batch, labels, k)\n",
        "        # class_disc_features = class_discriminator.predict(real_im) # get this classes' expected feature from class disc\n",
        "        # cd_input, _ = generate_GAN_samples(generator, input_dim, half_batch) # get noise for cd_feature input\n",
        "        # cd_feature_loss_local, _ = cd_feature.train_on_batch(cd_input, class_disc_features)\n",
        "        # cd_feature_loss += cd_feature_loss_local\n",
        "        \n",
        "        real_im, real_gan = generate_real_samples(dataset, half_batch, labels, k)\n",
        "        d_loss_real_local, _ = gan_discriminator.train_on_batch(real_im, real_gan) # gan loss real\n",
        "        d_loss_gan_disc_real += d_loss_real_local\n",
        "        fake_im, fake_gan = generate_fake_samples(generator, input_dim, half_batch)\n",
        "        d_loss_fake_local, _ = gan_discriminator.train_on_batch(fake_im, fake_gan) # gan loss fake\n",
        "        d_loss_gan_disc_fake += d_loss_fake_local\n",
        "\n",
        "        gan_input, inverted_label = generate_GAN_samples(generator, input_dim, half_batch) # returns with random noise for gan input\n",
        "        g_loss_local, _ = gan.train_on_batch(gan_input, inverted_label) # train generator with inverted labels via gan\n",
        "        g_loss += g_loss_local\n",
        "      # summarize loss on this batch\n",
        "      if (j+1) % n_batch == 0:\n",
        "        print(\"Epoch:\", i+1, \" - Batch:\",str(j+1)+\"/\"+str(batches_per_epoch),\n",
        "              \"avg_d_loss_gan (real/fake):\" + str(d_loss_gan_disc_real/len(labels)) + \",\" + str(d_loss_gan_disc_fake/len(labels)),\n",
        "              \"avg_gan_loss:\" + str(g_loss/len(labels)),\"cd_feature_loss:\" + str(cd_feature_loss/len(labels)))\n",
        "    # evaluate the model performance, sometimes\n",
        "    if (i+1) % 20 == 0:\n",
        "      for k in range(len(generators)):\n",
        "        summarize_performance(i, generators[k], gan_discriminators[k], dataset, input_dim, labels, class_names, k, sample_num)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35jPqfM7k6S-"
      },
      "source": [
        "# Init and Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12H6tp3NDcQU"
      },
      "source": [
        "# initializations before training\n",
        "# load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "class_names = ['zero', 'one', 'two', 'three', 'four',\n",
        "               'five', 'six', 'seven', 'eight', 'nine']\n",
        "# for tensorflow format (they assume 3rd dimension with color channels)\n",
        "train_images = np.expand_dims(train_images, 3)\n",
        "train_images = np.interp(train_images, (train_images.min(), train_images.max()), (-1, +1))\n",
        "\n",
        "test_images = np.expand_dims(test_images, 3)\n",
        "test_images = np.interp(test_images, (test_images.min(), test_images.max()), (-1, +1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyywK4qm3g80"
      },
      "source": [
        "im_shape = train_images[0].shape  # is the noise dim\n",
        "sample_num = 16 # make this a full square\n",
        "# length of noise vector for random generation\n",
        "label_shape = len(class_names)\n",
        "generator_input_dim = 100\n",
        "# init the generator array\n",
        "generators = []\n",
        "gans = []\n",
        "gan_discriminators = []\n",
        "class_discriminator = create_class_discriminator(im_shape, label_shape,)\n",
        "cd_features = []\n",
        "\n",
        "# create the generator array\n",
        "for i in range(label_shape):\n",
        "  generators.append(create_generator(generator_input_dim))\n",
        "  gan_discriminators.append(create_gan_discriminator(im_shape))\n",
        "  gans.append(create_gan(generators[i], gan_discriminators[i], generator_input_dim))\n",
        "  cd_features.append(create_class_discriminator_features(generators[i], class_discriminator, generator_input_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgHPtTZcf5QM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29071f77-f138-442f-dfe8-23acfe98b798"
      },
      "source": [
        "train(generators, gan_discriminators, gans, class_discriminator,  cd_features,\n",
        "      train_images, train_labels, generator_input_dim, sample_num, n_epochs=1000, \n",
        "      n_batch=1024)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a137a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f99337badd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 10 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a03e050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a2670e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a13d560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a2033b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a2e37a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a31e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f995038e680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f995028c170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a101b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f99502f65f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993aea4560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f99337ee710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a0f4ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7f993a03d7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: zero\n",
            ">real_eval: [0.7276002764701843, 0.3125]\n",
            ">fake_eval: [0.638041079044342, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: one\n",
            ">real_eval: [0.8450039625167847, 0.4375]\n",
            ">fake_eval: [0.8499484062194824, 0.3125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 20 || Class: two\n",
            ">real_eval: [0.6904574632644653, 0.5625]\n",
            ">fake_eval: [0.5706236958503723, 0.75]\n",
            "____________________\n",
            "WARNING:tensorflow:5 out of the last 185460 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f993a1010e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: three\n",
            ">real_eval: [0.578147292137146, 0.6875]\n",
            ">fake_eval: [0.4156903028488159, 0.9375]\n",
            "____________________\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f96a92c80e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 185461 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f993a264dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: four\n",
            ">real_eval: [0.4809624254703522, 0.8125]\n",
            ">fake_eval: [0.5016268491744995, 0.875]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f96a7de4200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 185462 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f993a310e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: five\n",
            ">real_eval: [0.5771577954292297, 0.8125]\n",
            ">fake_eval: [0.5583112239837646, 0.6875]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f96a69694d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 185463 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f993aeeb9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: six\n",
            ">real_eval: [0.43391168117523193, 0.8125]\n",
            ">fake_eval: [0.34674715995788574, 1.0]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f96a549b680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 185464 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f993aeeb050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: seven\n",
            ">real_eval: [0.6063838005065918, 0.625]\n",
            ">fake_eval: [0.6889560222625732, 0.5625]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f96a40347a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 185465 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f99500a0320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: eight\n",
            ">real_eval: [0.6017903685569763, 0.75]\n",
            ">fake_eval: [0.27700310945510864, 0.9375]\n",
            "____________________\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f96a2b51950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 185466 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f99337290e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "____________________\n",
            "Epoch: 20 || Class: nine\n",
            ">real_eval: [0.7161411046981812, 0.6875]\n",
            ">fake_eval: [0.6437544226646423, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: zero\n",
            ">real_eval: [0.750577986240387, 0.375]\n",
            ">fake_eval: [0.7190026044845581, 0.375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: one\n",
            ">real_eval: [0.7165493965148926, 0.25]\n",
            ">fake_eval: [0.6993798017501831, 0.3125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: two\n",
            ">real_eval: [0.7579818964004517, 0.5625]\n",
            ">fake_eval: [0.6887022852897644, 0.4375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: three\n",
            ">real_eval: [0.67826247215271, 0.625]\n",
            ">fake_eval: [0.6047647595405579, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: four\n",
            ">real_eval: [0.5838380455970764, 0.625]\n",
            ">fake_eval: [0.6653952598571777, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: five\n",
            ">real_eval: [0.5022501945495605, 0.75]\n",
            ">fake_eval: [0.546410083770752, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: six\n",
            ">real_eval: [0.6079151034355164, 0.75]\n",
            ">fake_eval: [0.5060447454452515, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: seven\n",
            ">real_eval: [0.6752369403839111, 0.625]\n",
            ">fake_eval: [0.7205560207366943, 0.375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: eight\n",
            ">real_eval: [0.6212151050567627, 0.5]\n",
            ">fake_eval: [0.4325529932975769, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 40 || Class: nine\n",
            ">real_eval: [0.6419922709465027, 0.6875]\n",
            ">fake_eval: [0.5543786883354187, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: zero\n",
            ">real_eval: [0.6625738143920898, 0.6875]\n",
            ">fake_eval: [0.6156295537948608, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: one\n",
            ">real_eval: [0.7228415608406067, 0.4375]\n",
            ">fake_eval: [0.6547249555587769, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: two\n",
            ">real_eval: [0.606453537940979, 0.6875]\n",
            ">fake_eval: [0.5177667140960693, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: three\n",
            ">real_eval: [0.6058070659637451, 0.6875]\n",
            ">fake_eval: [0.5005087852478027, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: four\n",
            ">real_eval: [0.6274958848953247, 0.75]\n",
            ">fake_eval: [0.7309378385543823, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: five\n",
            ">real_eval: [0.6609736680984497, 0.625]\n",
            ">fake_eval: [0.4979117512702942, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: six\n",
            ">real_eval: [0.5867253541946411, 0.6875]\n",
            ">fake_eval: [0.652938961982727, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: seven\n",
            ">real_eval: [0.5803424715995789, 0.75]\n",
            ">fake_eval: [0.7250326871871948, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: eight\n",
            ">real_eval: [0.588517427444458, 0.8125]\n",
            ">fake_eval: [0.6944892406463623, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 60 || Class: nine\n",
            ">real_eval: [0.6361083984375, 0.75]\n",
            ">fake_eval: [0.5354991555213928, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: zero\n",
            ">real_eval: [0.5873628854751587, 0.6875]\n",
            ">fake_eval: [0.6277147531509399, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: one\n",
            ">real_eval: [0.722583532333374, 0.5625]\n",
            ">fake_eval: [0.5771036744117737, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: two\n",
            ">real_eval: [0.6237694621086121, 0.625]\n",
            ">fake_eval: [0.7098710536956787, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: three\n",
            ">real_eval: [0.863837718963623, 0.6875]\n",
            ">fake_eval: [0.5205973386764526, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: four\n",
            ">real_eval: [0.6759205460548401, 0.375]\n",
            ">fake_eval: [0.5610143542289734, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: five\n",
            ">real_eval: [0.5502723455429077, 0.75]\n",
            ">fake_eval: [0.43393099308013916, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: six\n",
            ">real_eval: [0.6586064696311951, 0.625]\n",
            ">fake_eval: [0.6084507703781128, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: seven\n",
            ">real_eval: [0.6503642201423645, 0.5625]\n",
            ">fake_eval: [0.6519625782966614, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: eight\n",
            ">real_eval: [0.6519944667816162, 0.5625]\n",
            ">fake_eval: [0.6396934390068054, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 80 || Class: nine\n",
            ">real_eval: [0.6747561097145081, 0.5625]\n",
            ">fake_eval: [0.4510915279388428, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: zero\n",
            ">real_eval: [0.644530177116394, 0.8125]\n",
            ">fake_eval: [0.7230836749076843, 0.4375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: one\n",
            ">real_eval: [0.6232199668884277, 0.75]\n",
            ">fake_eval: [0.6730084419250488, 0.4375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: two\n",
            ">real_eval: [0.6206660866737366, 0.5]\n",
            ">fake_eval: [0.931671142578125, 0.5]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: three\n",
            ">real_eval: [0.51932692527771, 0.75]\n",
            ">fake_eval: [0.6050474047660828, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: four\n",
            ">real_eval: [0.5840634703636169, 0.75]\n",
            ">fake_eval: [0.39909371733665466, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: five\n",
            ">real_eval: [0.6791290640830994, 0.5]\n",
            ">fake_eval: [0.620540976524353, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: six\n",
            ">real_eval: [0.614963173866272, 0.6875]\n",
            ">fake_eval: [0.5930962562561035, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: seven\n",
            ">real_eval: [0.5742276906967163, 0.6875]\n",
            ">fake_eval: [0.5904185175895691, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: eight\n",
            ">real_eval: [0.7915494441986084, 0.5]\n",
            ">fake_eval: [0.7361395359039307, 0.3125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 100 || Class: nine\n",
            ">real_eval: [0.5977680087089539, 0.6875]\n",
            ">fake_eval: [0.582432746887207, 0.75]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: zero\n",
            ">real_eval: [0.6561475992202759, 0.75]\n",
            ">fake_eval: [0.7302908897399902, 0.3125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: one\n",
            ">real_eval: [0.7071970701217651, 0.5]\n",
            ">fake_eval: [0.6408786177635193, 0.625]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: two\n",
            ">real_eval: [0.4637320637702942, 0.8125]\n",
            ">fake_eval: [0.3840932548046112, 1.0]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: three\n",
            ">real_eval: [0.6187887191772461, 0.5]\n",
            ">fake_eval: [0.5353845357894897, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: four\n",
            ">real_eval: [0.7142650485038757, 0.5]\n",
            ">fake_eval: [0.6339660882949829, 0.6875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: five\n",
            ">real_eval: [0.4701226055622101, 0.8125]\n",
            ">fake_eval: [0.5223239064216614, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: six\n",
            ">real_eval: [0.6773110032081604, 0.4375]\n",
            ">fake_eval: [0.5219115018844604, 0.875]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: seven\n",
            ">real_eval: [0.42463189363479614, 1.0]\n",
            ">fake_eval: [0.4732762575149536, 0.9375]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: eight\n",
            ">real_eval: [0.6977947950363159, 0.5625]\n",
            ">fake_eval: [0.6091762781143188, 0.8125]\n",
            "____________________\n",
            "____________________\n",
            "Epoch: 120 || Class: nine\n",
            ">real_eval: [0.6222683787345886, 0.875]\n",
            ">fake_eval: [0.736665666103363, 0.4375]\n",
            "____________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-57228b75431d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train(generators, gan_discriminators, gans, class_discriminator,  cd_features,\n\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_input_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       n_batch=1024)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-e357ab6a5e5c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(generators, gan_discriminators, gans, class_discriminator, cd_features, dataset, labels, input_dim, sample_num, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0md_loss_gan_disc_real\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss_real_local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mfake_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0md_loss_fake_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_gan\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gan loss fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0md_loss_gan_disc_fake\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss_fake_local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m     \"\"\"\n\u001b[1;32m   1668\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   def train_on_batch(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3704\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3706\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    891\u001b[0m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[1;32m    892\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 893\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    894\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 142\u001b[0;31m         _ctx, \"AssignVariableOp\", name, resource, value)\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGFk7tbSUA9T"
      },
      "source": [
        "show_rand_plot(generator, im_shape, sample_num, train_labels, class_names, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN2_KMGaUZ8r"
      },
      "source": [
        "import time\n",
        "for i in range(12):\n",
        "  time.sleep(60*60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfWfiPKVcu8_"
      },
      "source": [
        "# Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWLLYai_c38g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939ec6a9-2059-4855-d15d-c7444f0c54c9"
      },
      "source": [
        "# initializations before training\n",
        "# load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "class_names = ['zero', 'one', 'two', 'three', 'four',\n",
        "               'five', 'six', 'seven', 'eight', 'nine']\n",
        "# for tensorflow format (they assume 3rd dimension with color channels)\n",
        "train_images = np.expand_dims(train_images, 3)\n",
        "train_images = np.interp(train_images, (train_images.min(), train_images.max()), (-1, +1))\n",
        "\n",
        "test_images = np.expand_dims(test_images, 3)\n",
        "test_images = np.interp(test_images, (test_images.min(), test_images.max()), (-1, +1))\n",
        "im_shape = train_images[0].shape  # is the noise dim\n",
        "sample_num = 16 # make this a full square\n",
        "# length of noise vector for random generation\n",
        "label_shape = len(class_names)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJXKn6SUfqMO"
      },
      "source": [
        "generator_input_dim = 100\n",
        "# init the generator array\n",
        "original_generator = []\n",
        "new_generator = []"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "XwMGR2QKg6k0",
        "outputId": "deb2a85d-f410-40bc-f939-8cf7f8808f6f"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  for filename in os.listdir('class/'):\n",
        "      if filename.endswith(str(i) + \".h5\"):\n",
        "        model = tf.keras.models.load_model('class/' + filename, custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU()})\n",
        "        optimizerfn = tf.keras.optimizers.Adam(learning_rate=.0001, beta_1=.9)\n",
        "        model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=optimizerfn, metrics=['accuracy'])\n",
        "        new_generator.append(model)\n",
        "for i in range(10):\n",
        "  for filename in os.listdir('noclass/'):\n",
        "      if filename.endswith(str(i) + \".h5\"):\n",
        "        model = tf.keras.models.load_model('noclass/' + filename, custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU()})\n",
        "        optimizerfn = tf.keras.optimizers.Adam(learning_rate=.0001, beta_1=.9)\n",
        "        model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=optimizerfn, metrics=['accuracy'])\n",
        "        original_generator.append(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1eb1ffa7efcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'LeakyReLU'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'class/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqPNT1Tzj5ma",
        "outputId": "813e3d79-0361-4778-8ab7-2d7deca16cba"
      },
      "source": [
        "from keras.models import load_model\n",
        "load_model('class/generator_model_120_0.h5', custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f65f0380950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4tQZIKCgjRN"
      },
      "source": [
        "input_dim = 100\n",
        "num_samples = 10\n",
        "def generate_output_images(generator, input_dim, num_samples):\n",
        "  # generate noise input for GAN with randomness and it's own prediction\n",
        "  inputs = np.random.randn(input_dim*num_samples)\n",
        "  # reshape into dimensions for the network\n",
        "  inputs = inputs.reshape(num_samples, input_dim)\n",
        "  fake_im = generator.predict(inputs)\n",
        "  return fake_im\n",
        "\n",
        "def generate_all_output_images(generators, dataset, input_dim, num_samples, name):\n",
        "  for i in range(len(generators)):\n",
        "    examples = generate_output_images(generators[i], input_dim, num_samples)\n",
        "    for k in range(num_samples):\n",
        "      pyplot.subplot(len(generators), num_samples, i*num_samples + 1 + k)\n",
        "      pyplot.axis('off')\n",
        "      pyplot.imshow(examples[k,:,:,0], cmap=\"gray\")\n",
        "      pyplot.margins(tight=True)\n",
        "      \n",
        "  pyplot.savefig(name, bbox_inches='tight', transparent=\"True\", pad_inches=0)\n",
        "  pyplot.close()\n",
        "generate_all_output_images(new_generator, train_images, input_dim, num_samples, \"new_generator.png\")\n",
        "generate_all_output_images(original_generator, train_images, input_dim, num_samples, \"original_generator.png\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uKjEPuTo-Fg"
      },
      "source": [
        "def generate_all_real_output_images(generators, dataset, labels, num_samples):\n",
        "  for i in range(len(generators)):\n",
        "    examples, _ = generate_real_samples(dataset, num_samples, labels, i)\n",
        "    for k in range(num_samples):\n",
        "      pyplot.subplot(len(generators), num_samples, i*num_samples + 1 + k)\n",
        "      pyplot.axis('off')\n",
        "      pyplot.imshow(examples[k,:,:,0], cmap=\"gray\")\n",
        "      pyplot.margins(tight=True)\n",
        "      \n",
        "  pyplot.savefig(\"real_images.png\", bbox_inches='tight', transparent=\"True\", pad_inches=0)\n",
        "  pyplot.close()\n",
        "generate_all_real_output_images(original_generator, train_images, train_labels, num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}